References
==========

@article{jain2021generating,
  title={Generating gender augmented data for NLP},
  author={Jain, Nishtha and Popovic, Maja and Groves, Declan and Vanmassenhove, Eva},
  journal={arXiv preprint arXiv:2107.05987},
  year={2021},
  url={https://aclanthology.org/2021.gebnlp-1.11}
}

@article{vanmassenhove2021gender,
  title={gENder-IT: An annotated English-Italian parallel challenge set for cross-linguistic natural gender phenomena},
  author={Vanmassenhove, Eva and Monti, Johanna},
  journal={arXiv preprint arXiv:2108.02854},
  year={2021},
  url={https://aclanthology.org/2021.gebnlp-1.1}
}

@article{vanmassenhove2021neutral,
  title={NeuTral Rewriter: A Rule-Based and Neural Approach to Automatic Rewriting into Gender-Neutral Alternatives},
  author={Vanmassenhove, Eva and Emmery, Chris and Shterionov, Dimitar},
  journal={arXiv preprint arXiv:2109.06105},
  year={2021},
  url={https://aclanthology.org/2021.emnlp-main.704}
}

@article{sharami2021selecting,
  title={Selecting Parallel In-domain Sentences for Neural Machine Translation Using Monolingual Texts},
  author={Sharami, Javad Pourmostafa Roshan and Shterionov, Dimitar and Spronck, Pieter},
  journal={arXiv preprint arXiv:2112.06096},
  year={2021},
  url={https://arxiv.org/abs/2112.06096}
}

@article{de2021defining,
  title={Defining meaningful units. Challenges in sign segmentation and segment-meaning mapping},
  author={De Sisto, Mirella and Shterionov, Dimitar and Murtagh, Irene and Vermeerbergen, Myriam and Leeson, Lorraine},
  journal={https://aclanthology. org/volumes/2021. mtsummit-at4ssl/},
  pages={98--103},
  year={2021},
  url={https://aclanthology.org/2021.mtsummit-at4ssl.11}
}

@inproceedings{shterionov2021early,
  title={Early-stage development of the SignON application and open framework--challenges and opportunities},
  author={Shterionov, Dimitar and O’Flaherty, John J and Keane, Edward and O’Reilly, Connor and Scipioni, Marcello Paolo and Giovanelli, Marco and Villa, Matteo},
  booktitle={Proceedings of Machine Translation Summit XVIII: Users and Providers Track},
  pages={277--290},
  year={2021},
  url={https://aclanthology.org/2021.mtsummit-up.20}
}

@article{delarosa2021,
  title={ Transformers analyzing poetry. {M}ultilingual metrical pattern prediction with transformer-based language models},
  author={{De la Rosa}, Javier and Álvaro Pérez and Mirella {De Sisto} and Laura Hernández and Aitor Diaz and Salvador Ros and Elena González Blanco},
  year={2021},
  journal={Neural Computing and Applications},
  publisher={Springer: London},
  url={https://link.springer.com/article/10.1007/s00521-021-06692-2}
}

@inproceedings{hernandez2021,
  title={The automatic quantitative metrical analysis of {Spanish Poetry with Rantanplan}: a first approach},
  author={Hernández-Lorenzo, Laura and De Sisto, Mirella and Álvaro Pérez and Javier {De la Rosa} and Salvador Ros and Elena González-Blanco},
  year={2021},
  editor={P. Plecháç and R. Kolár and A. Bories and J. Ríha},
  booktitle={Tackling the {Toolkit: Plotting Poetry through Computational Literary Studies}},
  pages={31--42},
  place={Prague: ICL CAS},
  url={https://www.plottingpoetry.org/books/tackling_toolkit/pdf/03_hernandez.pdf}
}

@inproceedings{sharami2022quality,
  title={Quality Estimation for the Translation Industry--Data Challenges},
  author={Sharami, Javad Pourmostafa Roshan and Murgolo, Elena and Shterionov, Dimitar},
  booktitle={The 32nd Meeting of Computational Linguistics in The Netherlands},
  year={2022},
  url={https://research.tilburguniversity.edu/en/publications/quality-estimation-for-the-translation-industry-data-challenges}
}

@inproceedings{de2022challenges,
  title={Challenges with sign language datasets for sign language recognition and translation},
  author={De Sisto, Mirella and Vandeghinste, Vincent and G{\'o}mez, Santiago Egea and De Coster, Mathieu and Shterionov, Dimitar and Seggion, H},
  booktitle={LREC2022, the 13th International Conference on Language Resources and Evaluation},
  pages={2478--2487},
  year={2022},
  url={https://aclanthology.org/2022.lrec-1.264}
}

@misc{https://doi.org/10.48550/arxiv.2202.02170,
  doi = {10.48550/ARXIV.2202.02170},
  url = {https://arxiv.org/abs/2202.02170},
  author = {Shterionov, Dimitar and Vanmassenhove, Eva},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {The Ecological Footprint of Neural Machine Translation Systems},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}

@inproceedings{murgolo2022quality,
  title={A Quality Estimation and Quality Evaluation Tool for the Translation Industry},
  author={Murgolo, Elena and Sharami, Javad Pourmostafa Roshan and Shterionov, Dimitar},
  booktitle={Proceedings of the 23rd Annual Conference of the European Association for Machine Translation},
  pages={305--306},
  year={2022},
  url={https://aclanthology.org/2022.eamt-1.43}
}

@article{desisto2022devoicing,
  title={Final Devoicing in Dutch Medieval and Renaissance Texts: A Preliminary Study on Orthographic Variation},
  author={De Sisto, Mirella},
  journal={Filologia Germanica - Germanic Philology. Germanic Philology and the Digital Paradigm: Models, Methods and Tools for Medieval Germanic Texts},
  year={2022}
}

@article{desisto2022cesura,
  title={Modelli di demarcazione della metà verso nel metro rinascimentale romanzo},
  author={De Sisto, Mirella},
  journal={Interruzioni e cesure. {F}enomeni e pratiche della discontinuità in linguistica, letteratura e arti performative},
  publisher={{ILLA} - {Nuove Ricerche Umanistiche}: {Pisa University Press}},
  year={2022}
}

@misc{boluki2023evaluating,
      title={Evaluating the Effectiveness of Pre-trained Language Models in Predicting the Helpfulness of Online Product Reviews}, 
      author={Ali Boluki and Javad Pourmostafa Roshan Sharami and Dimitar Shterionov},
      year={2023},
      eprint={2302.10199},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{sharami2023tailoring,
      title={Tailoring Domain Adaptation for Machine Translation Quality Estimation}, 
      author={Javad Pourmostafa Roshan Sharami and Dimitar Shterionov and Frédéric Blain and Eva Vanmassenhove and Mirella {De Sisto} and Chris Emmery and Pieter Spronck},
      year={2023},
      eprint={2304.08891},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{desisto2023ngthoreco,
      title = {A New English-Dutch-NGT Corpus for the Hospitality Domain},
      author = {De Sisto, Mirella and Vincent Vandeghinste and Dimitar Shterionov},
      year = {2023},
      booktitle = {Proceedings of the Second International Workshop on Automatic Translation for Signed and Spoken Languages}
}

@inproceedings{SignON_EAMT2023,
      title = {SignON: Sign Language Translation. Progress and challenges}, 
      author = {Vincent Vandeghinste and Dimitar Shterionov and Mirella {De Sisto} and Aoife Brady and Mathieu {De Coster} and Lorraine Leeson and Josep Blat and Frankie Picron and Marcello Paolo Scipioni and Aditya Parikh and Louis ten Bosch and John O’Flaherty and Joni Dambre and Jorn Rijckaert and Bram Vanroy and Victor Ubieto Nogales and Santiago Egea Gomez and Ineke Schuurman and Gorka Labaka and Adrian Nunez-Marcos and Irene Murtagh and Euan McGill and Horacio Saggion},
      year = {2023},
      booktitle = {Proceedings of the 24th Annual Conference of the European Association for Machine Translation}
}

@inproceedings{desisto2023gostparcsign,
      title = {GoSt-ParC-Sign: Gold Standard Parallel Corpus of Sign and spoken language},
      author = {De Sisto, Mirella and Vincent Vandeghinste and Lien Soetemans and Caro Brosens and Dimitar Shterionov},
      year = {2023},
      booktitle = {Proceedings of the 24th Annual Conference of the European Association for Machine Translation}
}

@misc{vandeghinste2023whitepaper,
      title = {Report on Europe’s Sign Languages. Deliverable European Language Equality II project},
      author = {Vincent Vandeghinste and Mirella {De Sisto} and Maria Kopf and Marc Schulder and Caro Brosens and Lien Soetemans and Rehana Omardeen and Frankie Picron and Davy Van Landuyt and Irene Murtagh and Eleftherios Avramidis and Mathieu {De Coster}},
      year = {2023},
      url = {https://european-language-equality.eu/wp-content/uploads/2023/06/ELE___Deliverable_D1_40__Europe_s_Sign_Languages_.pdf}
}

@inproceedings{silva-etal-2023-authorship,
    title = "Authorship Attribution of Late 19th Century Novels using {GAN}-{BERT}",
    author = "Silva, Kanishka  and
      Can, Burcu  and
      Blain, Fr{\'e}d{\'e}ric  and
      Sarwar, Raheem  and
      Ugolini, Laura  and
      Mitkov, Ruslan",
    editor = "Padmakumar, Vishakh  and
      Vallejo, Gisela  and
      Fu, Yao",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 4: Student Research Workshop)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-srw.44",
    doi = "10.18653/v1/2023.acl-srw.44",
    pages = "310--320",
    abstract = "Authorship attribution aims to identify the author of an anonymous text. The task becomes even more worthwhile when it comes to literary works. For example, pen names were commonly used by female authors in the 19th century resulting in some literary works being incorrectly attributed or claimed. With this motivation, we collated a dataset of late 19th century novels in English. Due to the imbalance in the dataset and the unavailability of enough data per author, we employed the GANBERT model along with data sampling strategies to fine-tune a transformer-based model for authorship attribution. Differently from the earlier studies on the GAN-BERT model, we conducted transfer learning on comparatively smaller author subsets to train more focused author-specific models yielding performance over 0.88 accuracy and F1 scores. Furthermore, we observed that increasing the sample size has a negative impact on the model{'}s performance. Our research mainly contributes to the ongoing authorship attribution research using GAN-BERT architecture, especially in attributing disputed novelists in the late 19th century.",
}


@article{8c9846437fb44bd6ada37326d26cb137,
title = "Text Data Augmentation Using Generative Adversarial Networks – A Systematic Review",
abstract = "Insufficient data is one of the main drawbacks in natural language processing tasks, and the most prevalent solution is to collect a decent amount of data that will be enough for the optimisation of the model. However, recent research directions are strategically moving towards increasing training examples due to the nature of the data-hungry neural models. Data augmentation is an emerging area that aims to ensure the diversity of data without attempting to collect new data exclusively to boost a model{\textquoteright}s performance. Limitations in data augmentation, especially for textual data, are mainly due to the nature of language data, which is precisely discrete. Generative Adversarial Networks (GANs) were initially introduced for computer vision applications, aiming to generate highly realistic images by learning the image representations. Recent research has focused on using GANs for text generation and augmentation. This systematic review aims to present the theoretical background of GANs and their use for text augmentation alongside a systematic review of recent textual data augmentation applications such as sentiment analysis, low resource language generation, hate speech detection and fraud review analysis. Further, a notion of challenges in current research and future directions of GAN-based text augmentation are discussed in this paper to pave the way for researchers especially working on low-text resources.",
keywords = "Text Data Augmentation, Generative Adversarial Networks, Adversarial Training, Text Generation",
author = "Kanishka Silva and Burcu Can and Raheem Sarwar and Fr{\'e}d{\'e}ric Blain and Ruslan Mitkov",
year = "2023",
month = jul,
day = "18",
doi = "10.33919/JCAL.23.1.1",
language = "English",
volume = "1",
pages = "6–38",
journal = "Journal of Computational and Applied Linguistics",

}

@inproceedings{freitag-etal-2023-results,
    title = "Results of {WMT}23 Metrics Shared Task: Metrics Might Be Guilty but References Are Not Innocent",
    author = "Freitag, Markus  and
      Mathur, Nitika  and
      Lo, Chi-kiu  and
      Avramidis, Eleftherios  and
      Rei, Ricardo  and
      Thompson, Brian  and
      Kocmi, Tom  and
      Blain, Fr{\'e}d{\'e}ric  and
      Deutsch, Daniel  and
      Stewart, Craig  and
      Zerva, Chrysoula  and
      Castilho, Sheila  and
      Lavie, Alon  and
      Foster, George",
    editor = "Koehn, Philipp  and
      Haddow, Barry  and
      Kocmi, Tom  and
      Monz, Christof",
    booktitle = "Proceedings of the Eighth Conference on Machine Translation",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.wmt-1.51",
    doi = "10.18653/v1/2023.wmt-1.51",
    pages = "578--628",
    abstract = "This paper presents the results of the WMT23 Metrics Shared Task. Participants submitting automatic MT evaluation metrics were asked to score the outputs of the translation systems competing in the WMT23 News Translation Task. All metrics were evaluated on how well they correlate with human ratings at the system and segment level. Similar to last year, we acquired our own human ratings based on expert-based human evaluation via Multidimensional Quality Metrics (MQM). Following last year{'}s success, we also included a challenge set subtask, where participants had to create contrastive test suites for evaluating metrics{'} ability to capture and penalise specific types of translation errors. Furthermore, we improved our meta-evaluation procedure by considering fewer tasks and calculating a global score by weighted averaging across the various tasks. We present an extensive analysis on how well metrics perform on three language pairs: Chinese-English, Hebrew-English on the sentence-level and English-German on the paragraph-level. The results strongly confirm the results reported last year, that neural-based metrics are significantly better than non-neural metrics in their levels of correlation with human judgments. Further, we investigate the impact of bad reference translations on the correlations of metrics with human judgment. We present a novel approach for generating synthetic reference translations based on the collection of MT system outputs and their corresponding MQM ratings, which has the potential to mitigate bad reference issues we observed this year for some language pairs. Finally, we also study the connections between the magnitude of metric differences and their expected significance in human evaluation, which should help the community to better understand and adopt new metrics.",
}

@inproceedings{blain-etal-2023-findings,
    title = "Findings of the {WMT} 2023 Shared Task on Quality Estimation",
    author = "Blain, Fr{\'e}d{\'e}ric  and
      Zerva, Chrysoula  and
      Ribeiro, Ricardo  and
      Guerreiro, Nuno M.  and
      Kanojia, Diptesh  and
      C. de Souza, Jos{\'e} G.  and
      Silva, Beatriz  and
      Vaz, T{\^a}nia  and
      Jingxuan, Yan  and
      Azadi, Fatemeh  and
      Orasan, Constantin  and
      Martins, Andr{\'e}",
    editor = "Koehn, Philipp  and
      Haddow, Barry  and
      Kocmi, Tom  and
      Monz, Christof",
    booktitle = "Proceedings of the Eighth Conference on Machine Translation",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.wmt-1.52",
    doi = "10.18653/v1/2023.wmt-1.52",
    pages = "629--653",
    abstract = "We report the results of the WMT 2023 shared task on Quality Estimation, in which the challenge is to predict the quality of the output of neural machine translation systems at the word and sentence levels, without access to reference translations. This edition introduces a few novel aspects and extensions that aim to enable more fine-grained, and explainable quality estimation approaches. We introduce an updated quality annotation scheme using Multidimensional Quality Metrics to obtain sentence- and word-level quality scores for three language pairs. We also extend the provided data to new language pairs: we specifically target low-resource languages and provide training, development and test data for English-Hindi, English-Tamil, English-Telegu and English-Gujarati as well as a zero-shot test-set for English-Farsi. Further, we introduce a novel fine-grained error prediction task aspiring to motivate research towards more detailed quality predictions.",
}


